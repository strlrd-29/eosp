This thesis presents the development and deployment of a Local Retrieval-Augmented Generation (RAG) agent using LLaMA3, an advanced language model. The proposed solution combines various state-of-the-art technologies, including FastAPI, Langchain, Langraph, Ollama, Docker, Docker Compose, and LangSmith, to create a robust and efficient system for information retrieval and answer generation. The agent leverages document retrieval techniques, model serving, answer validation, and self-correction mechanisms to provide accurate and comprehensive responses to user queries. The implementation details, including the high-level architecture, key components, data flow, and detailed workflow, are thoroughly discussed. Additionally, the thesis addresses the challenges encountered during the development process and presents the solutions implemented to overcome them. The integration of LangSmith for logging and monitoring further enhances the system's performance and reliability, enabling continuous improvement and optimization.
