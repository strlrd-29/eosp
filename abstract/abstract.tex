Hyko, currently functioning as a drag-and-drop AI tool builder, empowers users to connect multiple machine learning (ML) models and construct executable pipelines. However, a notable limitation lies in its incapacity to integrate user feedback, thus hampering the customization potential of its solutions. This thesis aims to bridge this gap by proposing a framework to enhance model performance through user-driven reinforcement learning. Our approach involves devising a system where users can provide online feedback and ratings, thereby deriving rewards for the model within a reinforcement learning paradigm. By doing so, we aspire to augment the customizability of solutions within the Hyko AI tool builder, paving the way for more adaptive and user-centric ML pipelines.
\\
\\
We detail the methodology for implementing this framework within the Hyko environment, including the design of user-friendly feedback interfaces and the integration of reinforcement learning algorithms. Practical evaluations demonstrate the feasibility and effectiveness of our approach across various domains, showcasing its potential for real-world applications.
\\
\\
This research contributes to advancing user-driven customization in AI systems, envisioning a future where ML solutions are not only powerful but also responsive to user preferences and evolving requirements.