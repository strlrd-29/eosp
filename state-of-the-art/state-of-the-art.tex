\chapter{State of the Art}
\graphicspath{{state-of-the-art/figures/}}

In recent years, the remarkable advancements in Natural Language Processing (NLP) have been primarily driven by the development of LLMs. These LLMs, such as GPT (Generative Pretrained Transformer) and BERT (Bidirectional Encoder Representations from Transformers), have demonstrated remarkable capabilities in understanding and generating human-like text. However, despite their impressive performance, LLMs still face challenges in effectively retrieving and incorporating relevant context for generating accurate and coherent responses.

Enter RAG systems, a novel approach that seeks to overcome the limitations of traditional LLMs by integrating retrieval mechanisms with generation models. RAG systems combine the strengths of both retrieval and generation techniques to enhance the quality and relevance of generated text.

This chapter provides a comprehensive exploration of RAG systems, delving into their architecture, components, training processes, applications, advantages, and challenges. We begin by establishing a foundational understanding of LLMs and their evolution, laying the groundwork for understanding the need for RAG systems. We then proceed to dissect the intricacies of RAG systems, discussing the role of retrieval in providing context and the role of generation in producing fluent responses.

Through detailed examination and analysis, we uncover the inner workings of RAG systems, exploring how retrieval and generation components interact within the architecture. Real-world applications and use cases of RAG systems across various domains are elucidated, demonstrating their potential to revolutionize tasks such as question answering, dialogue generation, and content creation.

Furthermore, we evaluate the advantages and limitations of RAG systems compared to traditional LLMs and other approaches in NLP. By examining performance metrics, challenges, and future directions, we gain insights into the transformative impact of RAG systems on the field of natural language processing.

In summary, this chapter serves as a comprehensive guide to RAG systems, offering readers a deep dive into one of the most promising advancements in NLP. As we navigate through the complexities and potentials of RAG systems, we pave the way for understanding their role in shaping the future of human-computer interaction and language understanding.

\section{Machine Learning}

\subsection{Definition}

Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Recently, artificial neural networks have been able to surpass many previous approaches in performance .

ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. When applied to business problems, it is known under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods \cite{enwiki:1220758567}.

\subsection{Relationships to other fields}

Artificial Intelligence (AI) encompasses the field of computer science dedicated to creating systems capable of emulating human-like intelligence, problem-solving, and decision-making. Machine Learning (ML) is a subset of AI focused on enabling computers to learn from data without being explicitly programmed. Within ML, Deep Learning stands out as a subfield that employs neural networks with multiple layers to learn complex representations of data, particularly effective in tasks like image and speech recognition. ML and Deep Learning are integral components of AI, providing the framework for developing intelligent systems capable of learning, reasoning, and adapting to new information, thereby advancing the capabilities of AI across various domains.

\begin{figure}[htpb]
    \centering
    \includegraphics[width=\textwidth,height=6cm,keepaspectratio=true]{ml.png}
    \caption{
        Machine learning as subfield of AI, from \cite{enwiki:1220758567}.
    }
\end{figure}

\subsection{Types of Machine Learning}

Machine Learning can be broadly categorized into several types based on the learning approach, the availability of labeled data, and the feedback mechanism. The main types of machine learning are:

\begin{figure}[htpb]
    \centering
    \includegraphics[width=\textwidth,height=6cm,keepaspectratio=true]{ml-types.pdf}
    \caption{
        Types of machine Learning.
    }
\end{figure}

\subsubsection*{Supervised Learning}

\begin{itemize}
    \item{In supervised learning, the algorithm learns from labeled data, where each input example is paired with the corresponding output label.}
    \item{The goal is to learn a mapping from inputs to outputs, allowing the algorithm to make predictions or classifications on unseen data.}
    \item{Common supervised learning tasks include regression (predicting continuous values) and classification (predicting discrete labels).}
\end{itemize}

\subsubsection*{Unsupervised Learning:}

\begin{itemize}
    \item{Unsupervised learning involves learning from unlabeled data, where the algorithm aims to find patterns, structures, or relationships in the data without explicit guidance.}
    \item{The algorithm discovers hidden structures or clusters within the data, facilitating tasks such as clustering, dimensionality reduction, and anomaly detection.}
\end{itemize}

\subsubsection*{Semi-Supervised Learning:}

\begin{itemize}
    \item{Semi-supervised learning lies between supervised and unsupervised learning, where the algorithm learns from a combination of labeled and unlabeled data.}
    \item{The presence of both labeled and unlabeled data allows the algorithm to leverage additional information and improve performance, particularly in scenarios where labeled data is scarce or expensive to obtain.}
\end{itemize}

\subsubsection*{Reinforcement Learning:}

\begin{itemize}
    \item{Reinforcement learning involves an agent learning to make decisions by interacting with an environment to achieve a specific goal.}
    \item{The agent receives feedback in the form of rewards or penalties based on its actions, enabling it to learn through trial and error.}
    \item{Reinforcement learning is commonly used in applications such as game playing, robotics, and autonomous systems.}
\end{itemize}

\subsection{Limitations of Machine Learning: Challenges and Considerations}

Although machine learning is a powerful technique for extracting knowledge from data, it also has certain limitations that are important to consider:

\begin{itemize}
    \item{\textbf{Data dependency:} Machine learning heavily relies on the quality and quantity of training data. If the data is poorly labeled or unrepresentative, it can lead to errors in predictions.}
    \item{\textbf{Overfitting:} When the model is too complex compared to the training data, it can overfit and not generalize well to test data. This can also result in poor performance for new data.}
    \item{\textbf{Explainability:} Machine learning models can be very complex and difficult to understand. It can be challenging to understand how the model makes decisions and to explain these decisions to users.}
    \item{\textbf{Biased data:} Training data can be biased due to factors such as data selection, human biases, or measurement errors. This can lead to biased predictions for test data.}
    \item{\textbf{Lack of diversity:} Machine learning models may lack diversity in the types of data they can handle. For example, machine learning models may struggle to process unstructured data such as images, sounds, and texts.}
    \item{\textbf{Computational cost:} Machine learning algorithms may require high computational power and significant storage resources to process large amounts of data. This can be costly and time-consuming to train and implement models.}
\end{itemize}


\section{Deep Learning}

\subsection{Definition}

Deep learning is the subset of machine learning methods based on artificial neural networks (ANNs) with representation learning. The adjective "deep" refers to the use of multiple layers in the network. Methods used can be either supervised, semi-supervised or unsupervised.

Deep-learning architectures such as deep neural networks, deep belief networks, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance \cite{enwiki:1220437155}.

\subsection{Deep Learning vs. Machine Learning}

Deep learning stands apart from traditional machine learning in its approach to data and learning methods.
Machine learning algorithms typically rely on structured, labeled data for predictions, where specific features are defined and organized into tables.
While machine learning can handle unstructured data, it often requires preprocessing to structure it. In contrast, deep learning streamlines this process by directly processing unstructured data such as text and images. It automates feature extraction, reducing reliance on human experts. For instance, in categorizing pet photos, deep learning algorithms autonomously identify key features, like ears, crucial for distinguishing between animals. In contrast, machine learning requires manual feature hierarchy establishment by human experts.

\subsection{Deep Learning Applications}

Deep learning has a wide range of applications across various domains due to its ability to learn complex patterns from large volumes of data. Some of the different types of applications for deep learning include:

\subsubsection*{Image Recognition and Computer Vision:}

\begin{itemize}
    \item Deep learning is extensively used for tasks such as image classification, object detection, facial recognition, and image segmentation.
    \item Applications include self-driving cars, medical image analysis, surveillance systems, and augmented reality.
\end{itemize}

\subsubsection*{Natural Language Processing (NLP):}

\begin{itemize}
    \item Deep learning is employed for understanding and generating human language, enabling tasks such as sentiment analysis, machine translation, text summarization, and chatbots.
    \item Applications include virtual assistants, language translation services, social media sentiment analysis, and customer support chatbots.
\end{itemize}

\subsubsection*{Speech Recognition and Synthesis:}

\begin{itemize}
    \item Deep learning is utilized for speech recognition, speech-to-text conversion, and text-to-speech synthesis.
    \item Applications include voice assistants, speech-to-text transcription services, voice-controlled devices, and interactive voice response systems.
\end{itemize}

\subsubsection*{Recommendation Systems:}

\begin{itemize}
    \item Deep learning is used to build personalized recommendation systems that analyze user preferences and behavior to suggest relevant products, content, or services.
    \item Applications include movie or music recommendation platforms, personalized advertising, and e-commerce product recommendations.
\end{itemize}

\subsubsection*{Autonomous Vehicles:}

\begin{itemize}
    \item Deep learning plays a crucial role in enabling autonomous vehicles to perceive and navigate their environment.
    \item Applications include object detection, lane detection, traffic sign recognition, and path planning for self-driving cars.
\end{itemize}

These are just a few examples of the diverse applications of deep learning, demonstrating its versatility and impact across various industries and fields.